{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SpartanFA/MachineLearningProjects/blob/main/Welcome_To_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "  <title>Benjamin Werner Robot Vision Assignment 2</title>\n",
        "</head>\n",
        "<body>\n",
        "  <h1>Robot Vision</h1>\n",
        "  <h2>Handwritten Digit Recognition Using Convolutional Neural Networks in Python with Keras</h2>\n",
        "  <p>Please follow the steps below after performing the steps for Part A.</p>\n",
        "  <p>Note: Select GPU in Google Colab for efficient results.</p>\n",
        "  <ol>\n",
        "    <li>Open Google Colab</li>\n",
        "    <li>Click on \"Runtime\" →</li>\n",
        "    <li>Click on \"Change runtime type\"</li>\n",
        "    <li>Select your \"Hardware accelerator\" to \"GPU\"</li>\n",
        "    <li>Click on SAVE</li>\n",
        "  </ol>\n",
        "  <p>Until this step, you have implemented and evaluated a simple Convolutional Neural Network for MNIST dataset. Now let’s implement another model architecture for MNIST.</p>\n",
        "  <h3>The Current Architecture used in Part A</h3>\n",
        "  <ul>\n",
        "    <li>Convolution neural network (with 32 channels) with relu activation function and with kernel of size (3,3)</li>\n",
        "    <code>layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\")</code>\n",
        "    <li>MaxPooling for 2D with a pool size of (2,2)</li>\n",
        "    <code>layers.MaxPooling2D(pool_size=(2, 2))</code>\n",
        "    <li>Convolution neural network (with 64 channels) with relu activation function and with kernel of size (3,3)</li>\n",
        "    <code>layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\")</code>\n",
        "    <li>MaxPooling for 2D with a pool size of (2,2)</li>\n",
        "    <code>layers.MaxPooling2D(pool_size=(2, 2))</code>\n",
        "    <li>Flatten layer</li>\n",
        "    <code>layers.Flatten()</code>\n",
        "    <li>Dropout layer with a probability of 50%</li>\n",
        "    <code>layers.Dropout(0.5)</code>\n",
        "    <li>Densely connected neural network with 10 output neurons and with softmax activation function</li>\n",
        "    <code>layers.Dense(num_classes, activation=\"softmax\")</code>\n",
        "  </ul>\n",
        "  <p>Now, for Part B, do the steps below:</p>\n",
        "  <h3>Robot Vision</h3>\n",
        "  <p>Follow the new model architecture (modify the code that was used for Part A)</p>\n",
        "  <ul>\n",
        "    <li>Create a convolution neural network (with 30 channels) with relu activation function and with kernel of size (5,5)</li>\n",
        "    <li>MaxPooling for 2D with a pool size of (2,2)</li>\n",
        "    <li>Create a convolution neural network (with 15 channels) with relu activation function and with kernel of size (3,3)</li>\n",
        "    <li>MaxPooling for 2D with a pool size of (2,2)</li>\n",
        "    <li>Dropout layer with a probability of 20%</li>\n",
        "    <li>Flatten layer</li>\n",
        "    <li>Densely connected neural network<li>Densely connected neural network with 128 output neurons and with relu activation function</li>\n",
        "    <li>Densely connected neural network with 50 output neurons and with relu activation function</li>\n",
        "    <li>Densely connected neural network with 10 output neurons and with softmax activation function</li>\n",
        "  </ul>\n",
        "  <p>The rest of the code should be as was used for Part A.</p>\n",
        "  <p>State which model (Part A or Part B) gives better accuracy (the last number coming out of the code) better. Then try to explain why the better model’s results are better. Deposit your Text answer in the submission portal on webcourses, and show the results of Part A and the results of Part B to the grader during the live grading.</p>\n",
        "</body>\n",
        "</html>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJBs_flRovLc"
      },
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "## **Part A**\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJr_9dXGpJ05",
        "outputId": "bb9090d5-b046-49f6-ddef-f0cd3616c8f3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                16010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34,826\n",
            "Trainable params: 34,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "422/422 [==============================] - 4s 6ms/step - loss: 0.3763 - accuracy: 0.8870 - val_loss: 0.0834 - val_accuracy: 0.9763\n",
            "Epoch 2/2\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1134 - accuracy: 0.9649 - val_loss: 0.0600 - val_accuracy: 0.9828\n",
            "Test loss: 0.06144927442073822\n",
            "Test accuracy: 0.980400025844574\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "# TRAIN THE MODEL\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 2\n",
        "np.random.seed(0)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "\n",
        "# EVALUATE THE MODEL\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "## **Part B**\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gE-Ez1qtyIA",
        "outputId": "e27cb68e-c018-4162-e9be-65328d642774",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 24, 24, 30)        780       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 12, 12, 30)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 10, 10, 15)        4065      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 5, 5, 15)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 5, 5, 15)          0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 375)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               48128     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 50)                6450      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                510       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 59,933\n",
            "Trainable params: 59,933\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/4\n",
            "422/422 [==============================] - 5s 7ms/step - loss: 0.3299 - accuracy: 0.8963 - val_loss: 0.0734 - val_accuracy: 0.9785\n",
            "Epoch 2/4\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0919 - accuracy: 0.9708 - val_loss: 0.0616 - val_accuracy: 0.9832\n",
            "Epoch 3/4\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0652 - accuracy: 0.9797 - val_loss: 0.0445 - val_accuracy: 0.9880\n",
            "Epoch 4/4\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0543 - accuracy: 0.9832 - val_loss: 0.0397 - val_accuracy: 0.9878\n",
            "Test loss: 0.02984199859201908\n",
            "Test accuracy: 0.9896000027656555\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(30, kernel_size=(5, 5), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(15, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        layers.Dense(50, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# TRAIN THE MODEL\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 2\n",
        "np.random.seed(0)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "# EVALUATE THE MODEL\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Different convolutional layers**: The modified model has a convolutional layer with 30 channels and a kernel size of (5, 5) followed by another convolutional layer with 15 channels and a kernel size of (3, 3). The larger kernel size of (5, 5) in the first layer may enable the model to capture more significant patterns in the MNIST images, such as larger stroke patterns, while the smaller kernel size of (3, 3) in the second layer can detect finer details. This combination might allow the model to learn a more diverse set of features from the handwritten digits, leading to better performance.\n",
        "\n",
        "**Additional dense layer**: The modified model has two extra dense layesr with ReLU activation function 50 output neurons and 10 output neurons. This additional layer increases the capacity of the model, enabling it to learn more complex relationships between the extracted features and the digit labels. Since the MNIST dataset is relatively small and simple, the increased capacity may help the model achieve slightly better accuracy without overfitting.\n",
        "\n",
        "**Lower dropout rate**: The modified model has a dropout rate of 20%, while the original model had a dropout rate of 50%. A lower dropout rate means that more neurons are active during training, which could lead to a slightly better performance. Given the simplicity and size of the MNIST dataset, reducing the dropout rate may not have a significant impact on overfitting and may allow the model to learn better representations of the digit images."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
